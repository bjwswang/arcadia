apiVersion: arcadia.kubeagi.k8s.com.cn/v1alpha1
kind: Application
metadata:
  name: chat-with-docs
  namespace: arcadia
spec:
  displayName: "对话机器人"
  description: "和AI对话，品赛博人生"
  prologue: "Hello, I am KubeAGI Bot🤖, Tell me something?"
  nodes:
    - name: Input
      displayName: "用户输入"
      description: "用户输入节点，必须"
      ref:
        kind: Input
        name: Input
      nextNodeName: ["prompt-node"]
    - name: prompt-node
      displayName: "prompt"
      description: "设定prompt，template中可以使用{{xx}}来替换变量"
      ref:
        apiGroup: prompt.arcadia.kubeagi.k8s.com.cn
        kind: Prompt
        name: base-chat-with-bot
      nextNodeName: ["chain-node"]
    - name: llm-node
      displayName: "zhipu大模型服务"
      description: "设定大模型的访问信息"
      ref:
        apiGroup: arcadia.kubeagi.k8s.com.cn
        kind: LLM
        name: app-shared-llm-service
      nextNodeName: ["chain-node"]
    - name: retriever-node
      displayName: "从对话过程中的文档提取信息的retriever"
      description: "连接文档"
      ref:
        apiGroup: retriever.arcadia.kubeagi.k8s.com.cn
        kind: ConversationRetriever
        name: base-chat-with-knowledgebase
      nextNodeName: ["chain-node"]
    - name: chain-node
      displayName: "llm chain"
      description: "chain是langchain的核心概念，llmChain用于连接prompt和llm"
      ref:
        apiGroup: chain.arcadia.kubeagi.k8s.com.cn
        kind: LLMChain
        name: base-chat-with-bot
      nextNodeName: ["Output"]
    - name: Output
      displayName: "最终输出"
      description: "最终输出节点，必须"
      ref:
        kind: Output
        name: Output
---
apiVersion: prompt.arcadia.kubeagi.k8s.com.cn/v1alpha1
kind: Prompt
metadata:
  name: base-chat-with-bot
  namespace: arcadia
  annotations:
    arcadia.kubeagi.k8s.com.cn/input-rules: '[{"kind":"Input","length":1}]'
    arcadia.kubeagi.k8s.com.cn/output-rules: '[{"length":1}]'
spec:
  displayName: "设定对话的prompt"
  description: "设定对话的prompt"
  userMessage: |
    The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.

    Current conversation:
    {{.history}}
    Human: {{.question}}
    AI:
---
apiVersion: chain.arcadia.kubeagi.k8s.com.cn/v1alpha1
kind: LLMChain
metadata:
  name: base-chat-with-bot
  namespace: arcadia
  annotations:
    arcadia.kubeagi.k8s.com.cn/input-rules: '[{"kind":"LLM","group":"arcadia.kubeagi.k8s.com.cn","length":1},{"kind":"prompt","group":"prompt.arcadia.kubeagi.k8s.com.cn","length":1}]'
    arcadia.kubeagi.k8s.com.cn/output-rules: '[{"kind":"Output","length":1}]'
spec:
  displayName: "llm chain"
  description: "llm chain"
  memory:
    conversionWindowSize: 2
  model: chatglm_turbo # notice: default model chatglm_lite gets poor results in most cases, openai's gpt-3.5-turbo is also good enough
---
apiVersion: retriever.kubeagi.k8s.com.cn/v1alpha1
kind: ConversationRetriever
metadata:
  name: conversationretriever-sample
spec:
spec:
  displayName: "从对话中获取信息的Retriever"
